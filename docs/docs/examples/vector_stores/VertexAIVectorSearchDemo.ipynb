{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akiva928/probable-octo-disco/blob/main/docs/docs/examples/vector_stores/VertexAIVectorSearchDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub6FTL_qhiKO"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/VertexAIVectorSearchDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agW8PzMnhiKQ"
      },
      "source": [
        "# Google Vertex AI Vector Search\n",
        "\n",
        "This notebook shows how to use functionality related to the `Google Cloud Vertex AI Vector Search` vector database.\n",
        "\n",
        "> [Google Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview), formerly known as Vertex AI Matching Engine, provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.\n",
        "\n",
        "**Note**: LlamaIndex expects Vertex AI Vector Search endpoint and deployed index is already created. An empty index creation time take upto a minute and deploying an index to the endpoint can take upto 30 min.\n",
        "\n",
        "> To see how to create an index refer to the section [Create Index and deploy it to an Endpoint](#create-index-and-deploy-it-to-an-endpoint)  \n",
        "If you already have an index deployed , skip to [Create VectorStore from texts](#create-vector-store-from-texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF5ZUr1ghiKR"
      },
      "source": [
        "## Installation\n",
        "\n",
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWqNYSJthiKS",
        "outputId": "28243cbc-6a83-4407-a771-604000dbebbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.14)\n",
            "Requirement already satisfied: llama-index-vector-stores-vertexaivectorsearch in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: llama-index-llms-vertex in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.14 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.14)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.14)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.2)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.4)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.39.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-vertexaivectorsearch) (1.74.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-vertexaivectorsearch) (2.19.0)\n",
            "Requirement already satisfied: llama-index-embeddings-vertex<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-vertexaivectorsearch) (0.3.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (4.25.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (24.2)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.10.6)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (1.6.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.59.9)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.14->llama-index) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (1.2.17)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (11.1.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.14->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.11)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.14->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.14.0)\n",
            "Requirement already satisfied: certifi<2025.0.0,>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2024.12.14)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.14->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.14->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.14->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.14->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.14->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.14->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.14->llama-index) (3.26.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install llama-index llama-index-vector-stores-vertexaivectorsearch llama-index-llms-vertex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW2vO8w8hiKT"
      },
      "source": [
        "## Create Index and deploy it to an Endpoint\n",
        "\n",
        "- This section demonstrates creating a new index and deploying it to an endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QgMxiG0hhiKU"
      },
      "outputs": [],
      "source": [
        "# TODO : Set values as per your requirements\n",
        "\n",
        "# Project and Storage Constants\n",
        "PROJECT_ID = \"personalized-reach-out\"\n",
        "REGION = \"us-central1\"\n",
        "GCS_BUCKET_NAME = f\"{PROJECT_ID}-embvs-your_gcs_bucket\"\n",
        "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\"\n",
        "\n",
        "# The number of dimensions for the textembedding-gecko@003 is 768\n",
        "# If other embedder is used, the dimensions would probably need to change.\n",
        "VS_DIMENSIONS = 768\n",
        "\n",
        "# Vertex AI Vector Search Index configuration\n",
        "# parameter description here\n",
        "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index\n",
        "VS_INDEX_NAME = \"llamaindex-doc-index\"  # @param {type:\"string\"}\n",
        "VS_INDEX_ENDPOINT_NAME = \"llamaindex-doc-endpoint\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FP7jqHDnhiKU"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate with gcloud:"
      ],
      "metadata": {
        "id": "9niGwN5_kH3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE-qz07GkCnu",
        "outputId": "050b2662-b890-43b0-f016-6f2e5689fe00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "It is recommended that you use service accounts for authentication.\n",
            "\n",
            "You can run:\n",
            "\n",
            "  $ gcloud config set account `ACCOUNT`\n",
            "\n",
            "to switch accounts if necessary.\n",
            "\n",
            "Your credentials may be visible to others with access to this\n",
            "virtual machine. Are you sure you want to authenticate with\n",
            "your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  \n",
            "\n",
            "Command killed by keyboard interrupt\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set your project:"
      ],
      "metadata": {
        "id": "XhgNvhSmlYbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !gcloud config set project personalized-reach-out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60stfPtqlZ3M",
        "outputId": "5c1e857b-5be5-49c8-889a-824215358f8a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp7oZVf4hiKV"
      },
      "source": [
        "### Create Cloud Storage bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REv3uGRmhiKV",
        "outputId": "6d5abf65-f0c8-43a6-d710-6a60df06769a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://personalized-reach-out-embvs-your_gcs_bucket/...\n"
          ]
        }
      ],
      "source": [
        "# Create a bucket.\n",
        "! gsutil mb -l $REGION -p {PROJECT_ID} {GCS_BUCKET_URI}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"GCS_BUCKET_URI: {GCS_BUCKET_URI}\")\n",
        "print(f\"GCS_BUCKET_NAME: {GCS_BUCKET_NAME}\")\n",
        "print(f\"PROJECT_ID: {PROJECT_ID}\")"
      ],
      "metadata": {
        "id": "9EHtczCyN1lb",
        "outputId": "b5c3bede-1d73-4576-8ec3-917e811b6aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCS_BUCKET_URI: gs://your_gcs_bucket\n",
            "GCS_BUCKET_NAME: your_gcs_bucket\n",
            "PROJECT_ID: personalized-reach-out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9gjveoIhiKV"
      },
      "source": [
        "### Create an empty Index\n",
        "\n",
        "**Note :** While creating an index you should specify an \"index_update_method\" - `BATCH_UPDATE` or `STREAM_UPDATE`\n",
        "\n",
        "> A batch index is for when you want to update your index in a batch, with data which has been stored over a set amount of time, like systems which are processed weekly or monthly.\n",
        ">\n",
        "> A streaming index is when you want index data to be updated as new data is added to your datastore, for instance, if you have a bookstore and want to show new inventory online as soon as possible.\n",
        ">\n",
        "> Which type you choose is important, since setup and requirements are different.\n",
        "\n",
        "Refer [Official Documentation](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index) and [API reference](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index) for more details on configuring indexes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import aiplatform\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Explicitly load credentials\n",
        "credentials_path = userdata.get('GOOGLE_APPLICATION_CREDENTIALS')\n",
        "if credentials_path:\n",
        "    credentials = service_account.Credentials.from_service_account_file(\n",
        "        credentials_path\n",
        "    )\n",
        "    aiplatform.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
        "else:\n",
        "    aiplatform.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "TBVdihHno_pt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkGa9LVBhiKW",
        "outputId": "107dc1ba-7573-46f0-91ac-99a8bbfd03db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Search index llamaindex-doc-index exists with resource name projects/697173753653/locations/us-central1/indexes/7338963038474600448\n"
          ]
        }
      ],
      "source": [
        "# NOTE : This operation can take upto 30 seconds\n",
        "\n",
        "# check if index exists\n",
        "index_names = [\n",
        "    index.resource_name\n",
        "    for index in aiplatform.MatchingEngineIndex.list(\n",
        "        filter=f\"display_name={VS_INDEX_NAME}\"\n",
        "    )\n",
        "]\n",
        "\n",
        "if len(index_names) == 0:\n",
        "    print(f\"Creating Vector Search index {VS_INDEX_NAME} ...\")\n",
        "    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "        display_name=VS_INDEX_NAME,\n",
        "        dimensions=VS_DIMENSIONS,\n",
        "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "        shard_size=\"SHARD_SIZE_SMALL\",\n",
        "        index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
        "        approximate_neighbors_count=20, # Add approximate_neighbors_count\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE7aEDt9hiKW"
      },
      "source": [
        "### Create an Endpoint\n",
        "\n",
        "To use the index, you need to create an index endpoint. It works as a server instance accepting query requests for your index. An endpoint can be a [public endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public) or a [private endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-vpc).\n",
        "\n",
        "Let's create a public endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYCbRxkHhiKW",
        "outputId": "2faca76d-dfac-4ec1-db13-70ac97ff6cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Search index endpoint llamaindex-doc-endpoint exists with resource name projects/697173753653/locations/us-central1/indexEndpoints/4588987700383580160\n"
          ]
        }
      ],
      "source": [
        "endpoint_names = [\n",
        "    endpoint.resource_name\n",
        "    for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n",
        "        filter=f\"display_name={VS_INDEX_ENDPOINT_NAME}\"\n",
        "    )\n",
        "]\n",
        "\n",
        "if len(endpoint_names) == 0:\n",
        "    print(\n",
        "        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n",
        "    )\n",
        "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
        "        index_endpoint_name=endpoint_names[0]\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr4BrPKChiKX"
      },
      "source": [
        "### Deploy Index to the Endpoint\n",
        "\n",
        "With the index endpoint, deploy the index by specifying a unique deployed index ID.\n",
        "\n",
        "**NOTE : This operation can take upto 30 minutes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_3806KhiKX",
        "outputId": "f8c2e40a-3ffc-4383-a93e-dc257fc809ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Search index llamaindex-doc-index is already deployed at endpoint llamaindex-doc-endpoint\n"
          ]
        }
      ],
      "source": [
        "# check if endpoint exists\n",
        "index_endpoints = [\n",
        "    (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
        "    for deployed_index in vs_index.deployed_indexes\n",
        "]\n",
        "\n",
        "if len(index_endpoints) == 0:\n",
        "    print(\n",
        "        f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
        "    )\n",
        "    vs_deployed_index = vs_endpoint.deploy_index(\n",
        "        index=vs_index,\n",
        "        deployed_index_id=VS_INDEX_NAME.replace('-', '_'),\n",
        "        display_name=VS_INDEX_NAME,\n",
        "        machine_type=\"e2-standard-16\",\n",
        "        min_replica_count=1,\n",
        "        max_replica_count=1,\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
        "        index_endpoint_name=index_endpoints[0][0]\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6UlM10fhiKX"
      },
      "source": [
        "## Create Vector Store from texts\n",
        "\n",
        "NOTE : If you have existing Vertex AI Vector Search Index and Endpoints, you can assign them using following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNw-Fc_MhiKX"
      },
      "outputs": [],
      "source": [
        "# TODO : replace 1234567890123456789 with your actual index ID\n",
        "vs_index = aiplatform.MatchingEngineIndex(index_name=\"1234567890123456789\")\n",
        "\n",
        "# TODO : replace 1234567890123456789 with your actual endpoint ID\n",
        "vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
        "    index_endpoint_name=\"1234567890123456789\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ql2IklmYhiKX"
      },
      "outputs": [],
      "source": [
        "# import modules needed\n",
        "from llama_index.core import (\n",
        "    StorageContext,\n",
        "    Settings,\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        ")\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.core.vector_stores.types import (\n",
        "    MetadataFilters,\n",
        "    MetadataFilter,\n",
        "    FilterOperator,\n",
        ")\n",
        "from llama_index.llms.vertex import Vertex\n",
        "from llama_index.embeddings.vertex import VertexTextEmbedding\n",
        "from llama_index.vector_stores.vertexaivectorsearch import VertexAIVectorStore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz4eB30xhiKY"
      },
      "source": [
        "### Create a simple vector store from plain text without metadata filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3uz2JQuxhiKY"
      },
      "outputs": [],
      "source": [
        "# setup storage\n",
        "\n",
        "vector_store = VertexAIVectorStore(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    index_id=vs_index.resource_name,\n",
        "    endpoint_id=vs_endpoint.resource_name,\n",
        "    gcs_bucket_name=GCS_BUCKET_NAME,\n",
        ")\n",
        "\n",
        "# set storage context\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhyB20vPhiKY"
      },
      "source": [
        "### Use [Vertex AI Embeddings](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/embeddings/llama-index-embeddings-vertex) as the embeddings model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qKPkqQi3hiKZ"
      },
      "outputs": [],
      "source": [
        "# configure embedding model\n",
        "embed_model = VertexTextEmbedding(\n",
        "    model_name=\"textembedding-gecko@003\",\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    credentials=credentials\n",
        ")\n",
        "\n",
        "# setup the index/query process, ie the embedding model (and completion if used)\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "048Gp-41hiKZ"
      },
      "source": [
        "### Add vectors and mapped text chunks to your vectore store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNv-wYkAhiKZ"
      },
      "outputs": [],
      "source": [
        "# Input texts\n",
        "texts = [\n",
        "    \"The cat sat on\",\n",
        "    \"the mat.\",\n",
        "    \"I like to\",\n",
        "    \"eat pizza for\",\n",
        "    \"dinner.\",\n",
        "    \"The sun sets\",\n",
        "    \"in the west.\",\n",
        "]\n",
        "nodes = [\n",
        "    TextNode(text=text, embedding=embed_model.get_text_embedding(text))\n",
        "    for text in texts\n",
        "]\n",
        "\n",
        "vector_store.add(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCbaIVVBhiKZ"
      },
      "source": [
        "### Running a similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HRT3GE0hiKZ"
      },
      "outputs": [],
      "source": [
        "# define index from vector store\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store=vector_store, embed_model=embed_model\n",
        ")\n",
        "retriever = index.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0p6rJSLhiKZ",
        "outputId": "c11e2b82-9b65-4aaf-a172-d0a5a873e1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 0.703 Text: eat pizza for\n",
            "Score: 0.626 Text: dinner.\n"
          ]
        }
      ],
      "source": [
        "response = retriever.retrieve(\"pizza\")\n",
        "for row in response:\n",
        "    print(f\"Score: {row.get_score():.3f} Text: {row.get_text()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_TT0_uRhiKb"
      },
      "source": [
        "## Add documents with metadata attributes and use filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJstbwHdhiKb",
        "outputId": "b7f9623d-36e4-417c-bdaa-1b1ae09e11e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Upserting datapoints MatchingEngineIndex index: projects/697173753653/locations/us-central1/indexes/7338963038474600448\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:MatchingEngineIndex index Upserted datapoints. Resource name: projects/697173753653/locations/us-central1/indexes/7338963038474600448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['93b4aac5-0516-475a-b174-8458728b7ed9',\n",
              " 'c853120b-828d-482f-9f66-37e0b57429f6',\n",
              " '48949bc4-7565-4a5e-bbdc-406b3c862e97',\n",
              " 'e4d4ce43-08a1-4f88-8c21-aaaf1a4ebaa5',\n",
              " 'c6b2aa6c-5d69-4484-8a25-0680190f09a6']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Input text with metadata\n",
        "records = [\n",
        "    {\n",
        "        \"description\": \"A versatile pair of dark-wash denim jeans.\"\n",
        "        \"Made from durable cotton with a classic straight-leg cut, these jeans\"\n",
        "        \" transition easily from casual days to dressier occasions.\",\n",
        "        \"price\": 65.00,\n",
        "        \"color\": \"blue\",\n",
        "        \"season\": [\"fall\", \"winter\", \"spring\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A lightweight linen button-down shirt in a crisp white.\"\n",
        "        \" Perfect for keeping cool with breathable fabric and a relaxed fit.\",\n",
        "        \"price\": 34.99,\n",
        "        \"color\": \"white\",\n",
        "        \"season\": [\"summer\", \"spring\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A soft, chunky knit sweater in a vibrant forest green. \"\n",
        "        \"The oversized fit and cozy wool blend make this ideal for staying warm \"\n",
        "        \"when the temperature drops.\",\n",
        "        \"price\": 89.99,\n",
        "        \"color\": \"green\",\n",
        "        \"season\": [\"fall\", \"winter\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A classic crewneck t-shirt in a soft, heathered blue. \"\n",
        "        \"Made from comfortable cotton jersey, this t-shirt is a wardrobe essential \"\n",
        "        \"that works for every season.\",\n",
        "        \"price\": 19.99,\n",
        "        \"color\": \"blue\",\n",
        "        \"season\": [\"fall\", \"winter\", \"summer\", \"spring\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A flowing midi-skirt in a delicate floral print. \"\n",
        "        \"Lightweight and airy, this skirt adds a touch of feminine style \"\n",
        "        \"to warmer days.\",\n",
        "        \"price\": 45.00,\n",
        "        \"color\": \"white\",\n",
        "        \"season\": [\"spring\", \"summer\"],\n",
        "    },\n",
        "]\n",
        "\n",
        "nodes = []\n",
        "for record in records:\n",
        "    text = record.pop(\"description\")\n",
        "    embedding = embed_model.get_text_embedding(text)\n",
        "    metadata = {**record}\n",
        "    nodes.append(TextNode(text=text, embedding=embedding, metadata=metadata))\n",
        "\n",
        "vector_store.add(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S8CctjyhiKb"
      },
      "source": [
        "### Running a similarity search with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qUbgHPNuhiKc"
      },
      "outputs": [],
      "source": [
        "# define index from vector store\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store=vector_store, embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jebjzTRhiKc",
        "outputId": "a05193ac-54f3-4c43-9efb-5f32ba113d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: A versatile pair of dark-wash denim jeans.Made from durable cotton with a classic straight-leg cut, these jeans transition easily from casual days to dressier occasions.\n",
            "   Score: 0.631\n",
            "   Metadata: {'price': 65.0, 'color': 'blue', 'season': ['fall', 'winter', 'spring']}\n",
            "Text: A flowing midi-skirt in a delicate floral print. Lightweight and airy, this skirt adds a touch of feminine style to warmer days.\n",
            "   Score: 0.585\n",
            "   Metadata: {'price': 45.0, 'color': 'white', 'season': ['spring', 'summer']}\n"
          ]
        }
      ],
      "source": [
        "# simple similarity search without filter\n",
        "retriever = index.as_retriever()\n",
        "response = retriever.retrieve(\"pants\")\n",
        "\n",
        "for row in response:\n",
        "    print(f\"Text: {row.get_text()}\")\n",
        "    print(f\"   Score: {row.get_score():.3f}\")\n",
        "    print(f\"   Metadata: {row.metadata}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAW3KH1lhiKc",
        "outputId": "69dd7ecd-eb3f-405b-e6d8-2cb4f863a472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: A versatile pair of dark-wash denim jeans.Made from durable cotton with a classic straight-leg cut, these jeans transition easily from casual days to dressier occasions.\n",
            "   Score: 0.704\n",
            "   Metadata: {'price': 65.0, 'color': 'blue', 'season': ['fall', 'winter', 'spring']}\n",
            "Text: A classic crewneck t-shirt in a soft, heathered blue. Made from comfortable cotton jersey, this t-shirt is a wardrobe essential that works for every season.\n",
            "   Score: 0.587\n",
            "   Metadata: {'price': 19.99, 'color': 'blue', 'season': ['fall', 'winter', 'summer', 'spring']}\n"
          ]
        }
      ],
      "source": [
        "# similarity search with text filter\n",
        "filters = MetadataFilters(filters=[MetadataFilter(key=\"color\", value=\"blue\")])\n",
        "retriever = index.as_retriever(filters=filters, similarity_top_k=3)\n",
        "response = retriever.retrieve(\"denims\")\n",
        "\n",
        "for row in response:\n",
        "    print(f\"Text: {row.get_text()}\")\n",
        "    print(f\"   Score: {row.get_score():.3f}\")\n",
        "    print(f\"   Metadata: {row.metadata}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CZHtTLlthiKd"
      },
      "outputs": [],
      "source": [
        "# similarity search with text and numeric filter\n",
        "filters = MetadataFilters(\n",
        "    filters=[\n",
        "        MetadataFilter(key=\"color\", value=\"blue\"),\n",
        "        MetadataFilter(key=\"price\", operator=FilterOperator.GT, value=70.0),\n",
        "    ]\n",
        ")\n",
        "retriever = index.as_retriever(filters=filters, similarity_top_k=3)\n",
        "response = retriever.retrieve(\"denims\")\n",
        "\n",
        "for row in response:\n",
        "    print(f\"Text: {row.get_text()}\")\n",
        "    print(f\"   Score: {row.get_score():.3f}\")\n",
        "    print(f\"   Metadata: {row.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBnrNK8JhiKd"
      },
      "source": [
        "## Parse, Index and Query PDFs using Vertex AI Vector Search and Gemini Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePJfAfIZhiKd",
        "outputId": "07fb048d-4841-42e0-ee52-69f62e087ea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E0501 00:56:50.842446801  266241 backup_poller.cc:127]                 Run client channel backup poller: UNKNOWN:pollset_work {created_time:\"2024-05-01T00:56:50.841935606+00:00\", children:[UNKNOWN:Bad file descriptor {created_time:\"2024-05-01T00:56:50.841810434+00:00\", errno:9, os_error:\"Bad file descriptor\", syscall:\"epoll_wait\"}]}\n",
            "--2024-05-01 00:56:52--  https://arxiv.org/pdf/1706.03762.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.195.42, 151.101.131.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://arxiv.org/pdf/1706.03762 [following]\n",
            "--2024-05-01 00:56:52--  http://arxiv.org/pdf/1706.03762\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2215244 (2.1M) [application/pdf]\n",
            "Saving to: ‘./data/arxiv/test.pdf’\n",
            "\n",
            "./data/arxiv/test.p 100%[===================>]   2.11M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-05-01 00:56:52 (31.5 MB/s) - ‘./data/arxiv/test.pdf’ saved [2215244/2215244]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! mkdir -p ./data/arxiv/\n",
        "! wget 'https://arxiv.org/pdf/1706.03762.pdf' -O ./data/arxiv/test.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQaT4dxThiKd",
        "outputId": "dad1bc59-fe3e-45f8-8a98-e8e810070b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of documents = 15\n"
          ]
        }
      ],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/arxiv/\").load_data()\n",
        "print(f\"# of documents = {len(documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MF83FYchiKd"
      },
      "outputs": [],
      "source": [
        "# setup storage\n",
        "vector_store = VertexAIVectorStore(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    index_id=vs_index.resource_name,\n",
        "    endpoint_id=vs_endpoint.resource_name,\n",
        "    gcs_bucket_name=GCS_BUCKET_NAME,\n",
        ")\n",
        "\n",
        "# set storage context\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# configure embedding model\n",
        "embed_model = VertexTextEmbedding(\n",
        "    model_name=\"textembedding-gecko@003\",\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "vertex_gemini = Vertex(\n",
        "    model=\"gemini-pro\",\n",
        "    context_window=100000,\n",
        "    temperature=0,\n",
        "    additional_kwargs={},\n",
        ")\n",
        "\n",
        "# setup the index/query process, ie the embedding model (and completion if used)\n",
        "Settings.llm = vertex_gemini\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9gb-nsDhiKe"
      },
      "outputs": [],
      "source": [
        "# define index from vector store\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H25smQuhhiKi"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvuQaSRJhiKj",
        "outputId": "8d907b24-3be0-40ae-8d18-4931b37679a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "--------------------------------------------------------------------------------\n",
            "The authors of the paper \"Attention Is All You Need\" are:\n",
            "\n",
            "* Ashish Vaswani\n",
            "* Noam Shazeer\n",
            "* Niki Parmar\n",
            "* Jakob Uszkoreit\n",
            "* Llion Jones\n",
            "* Aidan N. Gomez\n",
            "* Łukasz Kaiser\n",
            "* Illia Polosukhin\n",
            "--------------------------------------------------------------------------------\n",
            "Source Documents:\n",
            "--------------------------------------------------------------------------------\n",
            "Sample Text: Provided proper attribution is provided, Google he\n",
            "Relevance score: 0.720\n",
            "File Name: test.pdf\n",
            "Page #: 1\n",
            "File Path: /home/jupyter/llama_index/docs/docs/examples/vector_stores/data/arxiv/test.pdf\n",
            "--------------------------------------------------------------------------------\n",
            "Sample Text: length nis smaller than the representation dimensi\n",
            "Relevance score: 0.678\n",
            "File Name: test.pdf\n",
            "Page #: 7\n",
            "File Path: /home/jupyter/llama_index/docs/docs/examples/vector_stores/data/arxiv/test.pdf\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"who are the authors of paper Attention is All you need?\"\n",
        ")\n",
        "\n",
        "print(f\"Response:\")\n",
        "print(\"-\" * 80)\n",
        "print(response.response)\n",
        "print(\"-\" * 80)\n",
        "print(f\"Source Documents:\")\n",
        "print(\"-\" * 80)\n",
        "for source in response.source_nodes:\n",
        "    print(f\"Sample Text: {source.text[:50]}\")\n",
        "    print(f\"Relevance score: {source.get_score():.3f}\")\n",
        "    print(f\"File Name: {source.metadata.get('file_name')}\")\n",
        "    print(f\"Page #: {source.metadata.get('page_label')}\")\n",
        "    print(f\"File Path: {source.metadata.get('file_path')}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGiHNNk5hiKj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC-At7YPhiKj"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Please delete Vertex AI Vector Search Index and Index Endpoint after running your experiments to avoid incurring additional charges. Please note that you will be charged as long as the endpoint is running.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b>⚠️ NOTE: Enabling `CLEANUP_RESOURCES` flag deletes Vector Search Index, Index Endpoint and Cloud Storage bucket. Please run it with caution.</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s10t0EFfhiKk"
      },
      "outputs": [],
      "source": [
        "CLEANUP_RESOURCES = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7cAOCMHhiKk"
      },
      "source": [
        "- Undeploy indexes and Delete index endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UmjahDThiKk"
      },
      "outputs": [],
      "source": [
        "if CLEANUP_RESOURCES:\n",
        "    print(\n",
        "        f\"Undeploying all indexes and deleting the index endpoint {vs_endpoint.display_name}\"\n",
        "    )\n",
        "    vs_endpoint.undeploy_all()\n",
        "    vs_endpoint.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMIUv-EahiKk"
      },
      "source": [
        "- Delete index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5Fkl3nchiKk"
      },
      "outputs": [],
      "source": [
        "if CLEANUP_RESOURCES:\n",
        "    print(f\"Deleting the index {vs_index.display_name}\")\n",
        "    vs_index.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8q6r69fhiKl"
      },
      "source": [
        "- Delete contents from the Cloud Storage bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hhw6PyZhiKl"
      },
      "outputs": [],
      "source": [
        "if CLEANUP_RESOURCES and \"GCS_BUCKET_NAME\" in globals():\n",
        "    print(f\"Deleting contents from the Cloud Storage bucket {GCS_BUCKET_NAME}\")\n",
        "\n",
        "    shell_output = ! gsutil du -ash gs://$GCS_BUCKET_NAME\n",
        "    print(shell_output)\n",
        "    print(\n",
        "        f\"Size of the bucket {GCS_BUCKET_NAME} before deleting = {' '.join(shell_output[0].split()[:2])}\"\n",
        "    )\n",
        "\n",
        "    # uncomment below line to delete contents of the bucket\n",
        "    # ! gsutil -m rm -r gs://$GCS_BUCKET_NAME"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}